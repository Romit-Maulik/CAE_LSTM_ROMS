{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoders and LSTMs for PDE surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Lambda, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import optimizers, models, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SWE snapshot data - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load('../Equation_Based/snapshot_matrix_pod.npy').T\n",
    "\n",
    "# Scale the training data\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "# Transpose (rows are DOF, columns are snapshots)\n",
    "data = data.T\n",
    "\n",
    "swe_train_data = np.zeros(shape=(np.shape(data)[1],64,64,3)) # Channels last\n",
    "for i in range(np.shape(data)[1]):\n",
    "    temp_1 = data[0:64*64,i].reshape(64,64)\n",
    "    temp_2 = data[64*64:2*64*64,i].reshape(64,64)\n",
    "    temp_3 = data[2*64*64:3*64*64,i].reshape(64,64)\n",
    "    swe_train_data[i,:,:,0] = np.transpose(temp_1[:,:])\n",
    "    swe_train_data[i,:,:,1] = np.transpose(temp_2[:,:])\n",
    "    swe_train_data[i,:,:,2] = np.transpose(temp_3[:,:])\n",
    "    \n",
    "    \n",
    "data = np.load('../Equation_Based/snapshot_matrix_test.npy').T\n",
    "data = scaler.transform(data)\n",
    "# Transpose (rows are DOF, columns are snapshots)\n",
    "data = data.T\n",
    "\n",
    "swe_test_data = np.zeros(shape=(np.shape(data)[1],64,64,3)) # Channels last\n",
    "for i in range(np.shape(data)[1]):\n",
    "    temp_1 = data[0:64*64,i].reshape(64,64)\n",
    "    temp_2 = data[64*64:2*64*64,i].reshape(64,64)\n",
    "    temp_3 = data[2*64*64:3*64*64,i].reshape(64,64)\n",
    "    swe_test_data[i,:,:,0] = np.transpose(temp_1[:,:])\n",
    "    swe_test_data[i,:,:,1] = np.transpose(temp_2[:,:])\n",
    "    swe_test_data[i,:,:,2] = np.transpose(temp_3[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize train\n",
    "idx =  np.arange(swe_train_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "swe_train_data_randomized = swe_train_data[idx[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize one time instance of training\n",
    "time = 0\n",
    "fig, ax = plt.subplots(nrows=1,ncols=3)\n",
    "\n",
    "ax[0].imshow(swe_train_data[time,:,:,0])\n",
    "ax[1].imshow(swe_train_data[time,:,:,1])\n",
    "ax[2].imshow(swe_train_data[time,:,:,2])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize one time instance of testing\n",
    "fig, ax = plt.subplots(nrows=1,ncols=3)\n",
    "\n",
    "ax[0].imshow(swe_test_data[time,:,:,0])\n",
    "ax[1].imshow(swe_test_data[time,:,:,1])\n",
    "ax[2].imshow(swe_test_data[time,:,:,2])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5 # The window size of the LSTM\n",
    "mode = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML related presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "weights_filepath = 'best_weights_ae.h5'\n",
    "## Encoder\n",
    "encoder_inputs = Input(shape=(64,64,3),name='Field')\n",
    "# Encode   \n",
    "x = Conv2D(20,kernel_size=(3,3),activation='relu',padding='same')(encoder_inputs)\n",
    "enc_l2 = MaxPooling2D(pool_size=(2, 2),padding='same')(x)\n",
    "\n",
    "x = Conv2D(15,kernel_size=(3,3),activation='relu',padding='same')(enc_l2)\n",
    "enc_l3 = MaxPooling2D(pool_size=(2, 2),padding='same')(x)\n",
    "\n",
    "x = Conv2D(12,kernel_size=(3,3),activation='relu',padding='same')(enc_l3)\n",
    "enc_l4 = MaxPooling2D(pool_size=(2, 2),padding='same')(x)\n",
    "\n",
    "x = Conv2D(10,kernel_size=(3,3),activation='relu',padding='same')(enc_l4)\n",
    "enc_l5 = MaxPooling2D(pool_size=(2, 2),padding='same')(x)\n",
    "\n",
    "x = Conv2D(3,kernel_size=(3,3),activation=None,padding='same')(enc_l5)\n",
    "encoded = MaxPooling2D(pool_size=(2, 2),padding='same')(x)\n",
    "\n",
    "encoder = Model(inputs=encoder_inputs,outputs=encoded)\n",
    "    \n",
    "## Decoder\n",
    "decoder_inputs = Input(shape=(2,2,3),name='decoded')\n",
    "\n",
    "x = Conv2D(3,kernel_size=(3,3),activation='relu',padding='same')(decoder_inputs)\n",
    "dec_l1 = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(10,kernel_size=(3,3),activation='relu',padding='same')(dec_l1)\n",
    "dec_l2 = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(12,kernel_size=(3,3),activation='relu',padding='same')(dec_l2)\n",
    "dec_l3 = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(15,kernel_size=(3,3),activation='relu',padding='same')(dec_l3)\n",
    "dec_l4 = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(20,kernel_size=(3,3),activation='relu',padding='same')(dec_l4)\n",
    "dec_l5 = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "decoded = Conv2D(3,kernel_size=(3,3),activation=None,padding='same')(dec_l5)\n",
    "    \n",
    "decoder = Model(inputs=decoder_inputs,outputs=decoded)\n",
    "\n",
    "## Autoencoder\n",
    "ae_outputs = decoder(encoder(encoder_inputs))\n",
    "  \n",
    "model = Model(inputs=encoder_inputs,outputs=ae_outputs,name='CAE')\n",
    "\n",
    "plot_model(encoder,to_file='Encoder.png')\n",
    "plot_model(decoder,to_file='Decoder.png')\n",
    "    \n",
    "# design network\n",
    "my_adam = optimizers.Adam(lr=lrate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks_list = [checkpoint,earlystopping]\n",
    "\n",
    "# fit network\n",
    "model.compile(optimizer=my_adam,loss='mean_squared_error')    \n",
    "model.summary()\n",
    "\n",
    "num_epochs = 5000\n",
    "batch_size = 10\n",
    "\n",
    "if mode == 'train':\n",
    "    train_history = model.fit(x=swe_train_data_randomized, \n",
    "                              y=swe_train_data_randomized, \n",
    "                              epochs=num_epochs, batch_size=batch_size, \n",
    "                              callbacks=callbacks_list, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(weights_filepath)\n",
    "time = 10\n",
    "recoded_1 = model.predict(swe_train_data[time:time+1,:,:,:])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=3,figsize=(14,12))\n",
    "\n",
    "cs1 = ax[0,0].imshow(swe_train_data[time,:,:,0],label='input')\n",
    "ax[1,0].imshow(recoded_1[0,:,:,0],label='decoded')\n",
    "\n",
    "cs2 = ax[0,1].imshow(swe_train_data[time,:,:,1],label='input')\n",
    "ax[1,1].imshow(recoded_1[0,:,:,1],label='decoded')\n",
    "\n",
    "cs3 = ax[0,2].imshow(swe_train_data[time,:,:,2],label='input')\n",
    "ax[1,2].imshow(recoded_1[0,:,:,2],label='decoded')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[i,j].set_xlabel('x')\n",
    "        ax[i,j].set_ylabel('y')\n",
    "        \n",
    "fig.colorbar(cs1,ax=ax[0,0],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs1,ax=ax[1,0],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs2,ax=ax[0,1],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs2,ax=ax[1,1],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs3,ax=ax[0,2],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs3,ax=ax[1,2],fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "ax[0,0].set_title(r'True $q_1$')\n",
    "ax[0,1].set_title(r'True $q_2$')\n",
    "ax[0,2].set_title(r'True $q_3$')\n",
    "\n",
    "ax[1,0].set_title(r'Reconstructed $q_1$')\n",
    "ax[1,1].set_title(r'Reconstructed $q_2$')\n",
    "ax[1,2].set_title(r'Reconstructed $q_3$')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5,hspace=-0.3)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time = 10\n",
    "recoded_1 = model.predict(swe_test_data[time:time+1,:,:,:])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=3,figsize=(14,12))\n",
    "\n",
    "cs1 = ax[0,0].imshow(swe_test_data[time,:,:,0],label='input')\n",
    "ax[1,0].imshow(recoded_1[0,:,:,0],label='decoded')\n",
    "\n",
    "cs2 = ax[0,1].imshow(swe_test_data[time,:,:,1],label='input')\n",
    "ax[1,1].imshow(recoded_1[0,:,:,1],label='decoded')\n",
    "\n",
    "cs3 = ax[0,2].imshow(swe_test_data[time,:,:,2],label='input')\n",
    "ax[1,2].imshow(recoded_1[0,:,:,2],label='decoded')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[i,j].set_xlabel('x')\n",
    "        ax[i,j].set_ylabel('y')\n",
    "        \n",
    "fig.colorbar(cs1,ax=ax[0,0],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs1,ax=ax[1,0],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs2,ax=ax[0,1],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs2,ax=ax[1,1],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs3,ax=ax[0,2],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs3,ax=ax[1,2],fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "ax[0,0].set_title(r'True $q_1$')\n",
    "ax[0,1].set_title(r'True $q_2$')\n",
    "ax[0,2].set_title(r'True $q_3$')\n",
    "\n",
    "ax[1,0].set_title(r'Reconstructed $q_1$')\n",
    "ax[1,1].set_title(r'Reconstructed $q_2$')\n",
    "ax[1,2].set_title(r'Reconstructed $q_3$')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5,hspace=-0.3)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate encoded data for LSTM learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded = K.eval(encoder(swe_train_data[:,:,:,:].astype('float32')))\n",
    "# Latent space\n",
    "# print(np.shape(encoded))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(14,6))\n",
    "time = 98\n",
    "cs = ax[0].imshow(encoded[time,:,:,0])\n",
    "fig.colorbar(cs,ax=ax[0],fraction=0.046, pad=0.04)\n",
    "\n",
    "time = 198\n",
    "ax[1].imshow(encoded[time,:,:,0])\n",
    "fig.colorbar(cs,ax=ax[1],fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add parameter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parameter information\n",
    "parameters = np.load('../Equation_Based/Locations.npy')\n",
    "parameters_train = parameters[:90]\n",
    "parameters_test = parameters[90:]\n",
    "\n",
    "parameters = np.asarray([[-0.45, -0.25],[-0.15,  0.35],[-0.05, -0.45],[ 0.15,  0.45],\n",
    "        [ 0.05,  0.15],[-0.35,  0.05],[ 0.35, -0.05],[-0.25, -0.15],[ 0.45,  0.25],\n",
    "        [ 0.25, -0.35]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_training_data = np.copy(encoded)\n",
    "num_train_snapshots = 10\n",
    "total_size = np.shape(lstm_training_data)[0]*np.shape(lstm_training_data)[1]\n",
    "\n",
    "# Rescale\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scale_lstm = False\n",
    "if scale_lstm:\n",
    "    scaler = StandardScaler()\n",
    "    lstm_training_data_scaled = scaler.fit_transform(lstm_training_data[:,:])\n",
    "else:\n",
    "    lstm_training_data_scaled = lstm_training_data[:,:]\n",
    "    \n",
    "lstm_training_data_scaled = lstm_training_data_scaled.reshape(10,200,12)\n",
    "\n",
    "# Shape the inputs and outputs\n",
    "input_seq = np.zeros(shape=(total_size-time_window*num_train_snapshots,time_window,14))\n",
    "output_seq = np.zeros(shape=(total_size-time_window*num_train_snapshots,12))\n",
    "\n",
    "# Setting up inputs\n",
    "sample = 0\n",
    "for snapshot in range(num_train_snapshots):\n",
    "    lstm_snapshot = lstm_training_data_scaled[snapshot,:,:]\n",
    "    for t in range(time_window,200):\n",
    "        input_seq[sample,:,:12] = lstm_snapshot[t-time_window:t,:]\n",
    "        input_seq[sample,:,12:] = parameters[snapshot,:]\n",
    "        output_seq[sample,:] = lstm_snapshot[t,:]\n",
    "        sample = sample + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the training data (for future use)\n",
    "parameter_info = np.zeros(shape=(10,200,2),dtype='double')\n",
    "# Setting up inputs\n",
    "sample = 0\n",
    "for snapshot in range(num_train_snapshots):\n",
    "    for t in range(200):\n",
    "        parameter_info[snapshot,:,:] = parameters[snapshot,:]\n",
    "        \n",
    "total_training_data = np.concatenate((lstm_training_data_scaled,parameter_info),axis=-1)\n",
    "np.save('Times_Series_Training_Data.npy',total_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "lstm_model = models.Sequential()\n",
    "lstm_model.add(LSTM(50,input_shape=(time_window, 14),return_sequences=True))  #\n",
    "lstm_model.add(LSTM(50,input_shape=(time_window, 14),return_sequences=True))  #\n",
    "lstm_model.add(LSTM(50,input_shape=(time_window, 14),return_sequences=False))  #\n",
    "lstm_model.add(Dense(12, activation=None))\n",
    "\n",
    "# training parameters\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# design network\n",
    "lstm_filepath = 'lstm_weights.h5'\n",
    "lstm_adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "checkpoint = ModelCheckpoint(lstm_filepath, monitor='loss', verbose=0, save_best_only=True, mode='min',save_weights_only=True)\n",
    "earlystopping = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "lstm_callbacks_list = [checkpoint]\n",
    "\n",
    "# fit network\n",
    "lstm_model.compile(optimizer=lstm_adam,loss='mean_squared_error',metrics=[coeff_determination])\n",
    "\n",
    "if mode == 'train':\n",
    "    lstm_train_history = lstm_model.fit(input_seq, output_seq, epochs=num_epochs, batch_size=batch_size, callbacks=lstm_callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM with parameter information - on training data (stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_weights(lstm_filepath)\n",
    "# lstm_model.load_weights('lstm_weights_best.h5')\n",
    "\n",
    "# Shape the inputs and outputs\n",
    "input_seq = np.zeros(shape=(1,time_window,14))\n",
    "output_seq_pred = np.zeros(shape=(200,12))\n",
    "\n",
    "# Setting up inputs\n",
    "sample = 0\n",
    "input_seq[0,:,:] = total_training_data[0,0:time_window,:]\n",
    "input_seq[0,:,12] = total_training_data[0,0,12]\n",
    "input_seq[0,:,13] = total_training_data[0,0,13]\n",
    "\n",
    "output_seq_pred[:,:] = total_training_data[0,:,:12]\n",
    "\n",
    "for t in range(time_window,200):\n",
    "    output_seq_pred[t,:] = lstm_model.predict(input_seq[0:1,:,:])[0,:]\n",
    "    input_seq[0,0:time_window-1,:12] = input_seq[0,1:,:12] \n",
    "    input_seq[0,time_window-1,:12] = output_seq_pred[t,:]\n",
    "    sample = sample + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check quality in latent space for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.plot(total_training_data[0,:,i],'r',label='True',linewidth=3)\n",
    "    plt.plot(output_seq_pred[:,i],'b--',label='Predicted',linewidth=3)\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Training_LS_LSTM_'+str(i)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM with parameter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid = K.eval(encoder(swe_data_test[:,:,:,:].astype('float32')))\n",
    "encoded_valid = encoded_valid.reshape(1,200,12)\n",
    "lstm_testing_data = np.copy(encoded_valid)\n",
    "\n",
    "num_test_snapshots = 1\n",
    "\n",
    "# Shape the inputs and outputs\n",
    "input_seq = np.zeros(shape=(1,time_window,14))\n",
    "output_seq_pred = np.zeros(shape=(200,12))\n",
    "\n",
    "# Setting up inputs\n",
    "sample = 0\n",
    "input_seq[0,:,:12] = lstm_testing_data[0,0:time_window,:]\n",
    "input_seq[0,:,12] = 1.0/2.7\n",
    "input_seq[0,:,13] = 1.0/4.0\n",
    "\n",
    "output_seq_pred[:time_window,:] = lstm_testing_data[0,:time_window,:]\n",
    "\n",
    "for t in range(time_window,200):\n",
    "    output_seq_pred[t,:] = lstm_model.predict(input_seq[0:1,:,:])[0,:]\n",
    "    input_seq[0,0:time_window-1,:12] = input_seq[0,1:,:12] \n",
    "    input_seq[0,time_window-1,:12] = output_seq_pred[t,:]\n",
    "    sample = sample + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check quality in latent space for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.plot(lstm_testing_data[0,:,i],'r',label='True',linewidth=3)\n",
    "    plt.plot(output_seq_pred[:,i],'b--',label='Predicted',linewidth=3)\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Testing_LS_LSTM_'+str(i)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the testing data (for future use)\n",
    "parameter_info = np.zeros(shape=(1,200,2),dtype='double')\n",
    "# Setting up inputs\n",
    "parameter_info[0,:,0] = 1.0/2.7\n",
    "parameter_info[0,:,1] = 1.0/4.0\n",
    "    \n",
    "time_series_testing_data = np.concatenate((lstm_testing_data,parameter_info),axis=-1)\n",
    "np.save('Times_Series_Testing_Data.npy',time_series_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seq_pred = np.reshape(output_seq_pred,newshape=(200,2,2,3))\n",
    "print(np.shape(output_seq_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution in physical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GP data\n",
    "q1_snapshots_gp = np.load('q1_snapshots_gp.npy')\n",
    "q2_snapshots_gp = np.load('q2_snapshots_gp.npy')\n",
    "q3_snapshots_gp = np.load('q3_snapshots_gp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_valid = K.eval(decoder(output_seq_pred.astype('float32')))\n",
    "time = 199\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=3,figsize=(14,12))\n",
    "cs1 = ax[0,0].imshow(swe_data_test[time,:,:,0],label='Truth')\n",
    "ax[1,0].imshow(gaussian_filter(decoded_valid[time,:,:,0],sigma=2),label='Prediction')\n",
    "\n",
    "cs2 = ax[0,1].imshow(swe_data_test[time,:,:,1],label='Truth')\n",
    "ax[1,1].imshow(gaussian_filter(decoded_valid[time,:,:,1],sigma=2),label='Prediction')\n",
    "\n",
    "cs3 = ax[0,2].imshow(swe_data_test[time,:,:,2],label='Truth')\n",
    "ax[1,2].imshow(gaussian_filter(decoded_valid[time,:,:,2],sigma=2),label='Prediction')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[i,j].set_xlabel('x')\n",
    "        ax[i,j].set_ylabel('y')\n",
    "        \n",
    "fig.colorbar(cs1,ax=ax[0,0],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs1,ax=ax[1,0],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs2,ax=ax[0,1],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs2,ax=ax[1,1],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs3,ax=ax[0,2],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs3,ax=ax[1,2],fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "ax[0,0].set_title(r'True $q_1$')\n",
    "ax[0,1].set_title(r'True $q_2$')\n",
    "ax[0,2].set_title(r'True $q_3$')\n",
    "\n",
    "ax[1,0].set_title(r'Reconstructed $q_1$')\n",
    "ax[1,1].set_title(r'Reconstructed $q_2$')\n",
    "ax[1,2].set_title(r'Reconstructed $q_3$')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5,hspace=-0.3)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Testing_Data_Field_True.npy',swe_data_test)\n",
    "np.save('Testing_Data_Field_Prediction.npy',decoded_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A posteriori analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_test_true = np.load('Testing_Data_Field_True.npy')\n",
    "snapshot_test_pred = np.load('Testing_Data_Field_Prediction.npy')\n",
    "\n",
    "# Inverse transform\n",
    "snapshot_test_true = np.reshape(snapshot_test_true,newshape=(200,64*64*3),order='F')\n",
    "snapshot_test_pred = np.reshape(snapshot_test_pred,newshape=(200,64*64*3),order='F')\n",
    "\n",
    "snapshot_test_true = scaler.inverse_transform(snapshot_test_true)\n",
    "snapshot_test_pred = scaler.inverse_transform(snapshot_test_pred)\n",
    "\n",
    "snapshot_test_true = np.reshape(snapshot_test_true,newshape=(200,64,64,3),order='F')\n",
    "snapshot_test_pred = np.reshape(snapshot_test_pred,newshape=(200,64,64,3),order='F')\n",
    "\n",
    "np.save('Testing_Data_Field_True_Viz.npy',snapshot_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots for field values\n",
    "probe_data_true = np.mean(np.copy(snapshot_test_true).reshape(200,64*64,3,order='C'),axis=1)\n",
    "probe_data_pred = np.mean(np.copy(snapshot_test_pred).reshape(200,64*64,3,order='C'),axis=1)\n",
    "probe_data_gp_q1 = np.mean(np.copy(q1_snapshots_gp),axis=0)\n",
    "probe_data_gp_q2 = np.mean(np.copy(q2_snapshots_gp),axis=0)\n",
    "probe_data_gp_q3 = np.mean(np.copy(q3_snapshots_gp),axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,ncols=3,figsize=(15,5))\n",
    "ax[0].plot(probe_data_true[:,0],label='True')\n",
    "ax[0].plot(probe_data_pred[:,0],label='Predicted')\n",
    "ax[0].plot(probe_data_gp_q1[:],label='GP')\n",
    "ax[0].set_title(r'$q_1$')\n",
    "\n",
    "ax[1].plot(probe_data_true[:,1],label='True')\n",
    "ax[1].plot(probe_data_pred[:,1],label='Predicted')\n",
    "ax[1].plot(probe_data_gp_q2[:],label='GP')\n",
    "ax[1].set_title(r'$q_2$')\n",
    "\n",
    "ax[2].plot(probe_data_true[:,2],label='True')\n",
    "ax[2].plot(probe_data_pred[:,2],label='Predicted')\n",
    "ax[2].plot(probe_data_gp_q3[:],label='GP')\n",
    "ax[2].set_title(r'$q_3$')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_valid = K.eval(decoder(output_seq_pred.astype('float32')))\n",
    "time = 50\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3,ncols=3,figsize=(14,12))\n",
    "cs1 = ax[0,0].imshow(snapshot_test_true[time,:,:,0],label='Truth')\n",
    "ax[1,0].imshow(gaussian_filter(snapshot_test_pred[time,:,:,0],sigma=2),label='Prediction')\n",
    "ax[2,0].imshow(q1_snapshots_gp[:,time].reshape(64,64),label='GP')\n",
    "\n",
    "cs2 = ax[0,1].imshow(snapshot_test_true[time,:,:,1],label='Truth')\n",
    "ax[1,1].imshow(gaussian_filter(snapshot_test_pred[time,:,:,1],sigma=2),label='Prediction')\n",
    "ax[2,1].imshow(q2_snapshots_gp[:,time].reshape(64,64),label='GP')\n",
    "\n",
    "cs3 = ax[0,2].imshow(snapshot_test_true[time,:,:,2],label='Truth')\n",
    "ax[1,2].imshow(gaussian_filter(snapshot_test_pred[time,:,:,2],sigma=2),label='Prediction')\n",
    "ax[2,2].imshow(q3_snapshots_gp[:,time].reshape(64,64),label='GP')\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i,j].set_xlabel('x')\n",
    "        ax[i,j].set_ylabel('y')\n",
    "        \n",
    "fig.colorbar(cs1,ax=ax[0,0],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs1,ax=ax[1,0],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs1,ax=ax[2,0],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs2,ax=ax[0,1],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs2,ax=ax[1,1],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs2,ax=ax[2,1],fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.colorbar(cs3,ax=ax[0,2],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs3,ax=ax[1,2],fraction=0.046, pad=0.04)\n",
    "fig.colorbar(cs3,ax=ax[2,2],fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "ax[0,0].set_title(r'True $q_1$')\n",
    "ax[0,1].set_title(r'True $q_2$')\n",
    "ax[0,2].set_title(r'True $q_3$')\n",
    "\n",
    "ax[1,0].set_title(r'Reconstructed $q_1$')\n",
    "ax[1,1].set_title(r'Reconstructed $q_2$')\n",
    "ax[1,2].set_title(r'Reconstructed $q_3$')\n",
    "\n",
    "ax[2,0].set_title(r'GP $q_1$')\n",
    "ax[2,1].set_title(r'GP $q_2$')\n",
    "ax[2,2].set_title(r'GP $q_3$')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('CAE_GP_Contour_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1/2, 1/2, 64)  # Array with x-points\n",
    "y = np.linspace(-1/2, 1/2, 64)  # Array with x-points\n",
    "\n",
    "# Meshgrid for plotting\n",
    "X, Y = np.meshgrid(x, y)\n",
    "time = -1\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize = (11, 7))\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, snapshot_test_true[time,:,:,0], rstride = 1, cstride = 1,\n",
    "    cmap = plt.cm.jet, linewidth = 0, antialiased = True)\n",
    "\n",
    "# ax.set_title('Visualization', fontname = \"serif\", fontsize = 17)\n",
    "ax.set_xlabel('x [m]', fontsize = 16)\n",
    "ax.set_ylabel('y [m]', fontsize = 16)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=15)\n",
    "\n",
    "# ax.set_zticks([0.1, 0.15, 0.20, 0.25, 0.3])\n",
    "ax.set_zlim((0.9,1.1))\n",
    "\n",
    "plt.savefig('True_q1_field.png')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (11, 7))\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, gaussian_filter(snapshot_test_pred[time,:,:,0],sigma=2), rstride = 1, cstride = 1,\n",
    "    cmap = plt.cm.jet, linewidth = 0, antialiased = True)\n",
    "\n",
    "# ax.set_title('Visualization', fontname = \"serif\", fontsize = 17)\n",
    "ax.set_xlabel('x [m]', fontsize = 16)\n",
    "ax.set_ylabel('y [m]', fontsize = 16)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "# ax.set_zticks([0.1, 0.15, 0.20, 0.25, 0.3])\n",
    "ax.set_zlim((0.9,1.1))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=15)\n",
    "plt.savefig('Pred_q1_field.png')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (11, 7))\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, snapshot_test_true[time,:,:,1], rstride = 1, cstride = 1,\n",
    "    cmap = plt.cm.jet, linewidth = 0, antialiased = True)\n",
    "\n",
    "# ax.set_title('Visualization', fontname = \"serif\", fontsize = 17)\n",
    "ax.set_xlabel('x [m]', fontsize = 16)\n",
    "ax.set_ylabel('y [m]', fontsize = 16)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=15)\n",
    "\n",
    "# ax.set_zticks([-0.1, -0.05, 0.0, 0.05, 0.1])\n",
    "ax.set_zlim((-0.1,0.1))\n",
    "\n",
    "plt.savefig('True_q2_field.png')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (11, 7))\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, gaussian_filter(snapshot_test_pred[time,:,:,1],sigma=2), rstride = 1, cstride = 1,\n",
    "    cmap = plt.cm.jet, linewidth = 0, antialiased = True)\n",
    "\n",
    "# ax.set_title('Visualization', fontname = \"serif\", fontsize = 17)\n",
    "ax.set_xlabel('x [m]', fontsize = 16)\n",
    "ax.set_ylabel('y [m]', fontsize = 16)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "# ax.set_zticks([-0.1, -0.05, 0.0, 0.05, 0.1])\n",
    "ax.set_zlim((-0.1,0.1))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=15)\n",
    "plt.savefig('Pred_q2_field.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (11, 7))\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, snapshot_test_true[time,:,:,2], rstride = 1, cstride = 1,\n",
    "    cmap = plt.cm.jet, linewidth = 0, antialiased = True)\n",
    "\n",
    "# ax.set_title('Visualization', fontname = \"serif\", fontsize = 17)\n",
    "ax.set_xlabel('x [m]', fontsize = 16)\n",
    "ax.set_ylabel('y [m]', fontsize = 16)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=15)\n",
    "\n",
    "# ax.set_zticks([-0.2,-0.15,-0.1, -0.05, 0.0, 0.05, 0.1, 0.15,0.2])\n",
    "ax.set_zlim((-0.3,0.2))\n",
    "\n",
    "plt.savefig('True_q3_field.png')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (11, 7))\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, gaussian_filter(snapshot_test_pred[time,:,:,2],sigma=2), rstride = 1, cstride = 1,\n",
    "    cmap = plt.cm.jet, linewidth = 0, antialiased = True)\n",
    "\n",
    "# ax.set_title('Visualization', fontname = \"serif\", fontsize = 17)\n",
    "ax.set_xlabel('x [m]', fontsize = 16)\n",
    "ax.set_ylabel('y [m]', fontsize = 16)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "\n",
    "# ax.set_zticks([-0.2,-0.15,-0.1, -0.05, 0.0, 0.05, 0.1, 0.15,0.2])\n",
    "ax.set_zlim((-0.3,0.2))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=15)\n",
    "plt.savefig('Pred_q3_field.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
